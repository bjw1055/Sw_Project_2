# -*- coding: utf-8 -*-
import pandas as pd
from prophet import Prophet
import re
import matplotlib
matplotlib.use('Agg')
import io
import sys
import json
import os
import requests
import mysql.connector
import chardet

# MySQL ì—°ê²°
def get_db_connection():
    return mysql.connector.connect(
        host='localhost',
        user='root',
        password='0000',
        database='dashboard_db'
    )

# ì»¬ëŸ¼ ì¶”ì • í•¨ìˆ˜
def guess_column(candidates, options):
    for col in candidates:
        for opt in options:
            if re.search(opt, col, re.IGNORECASE):
                return col
    return None

COLUMN_ALIASES = {
    'íŒë§¤ì¼': 'ë‚ ì§œ',
    'date': 'ë‚ ì§œ',
    'Date': 'ë‚ ì§œ',
    'íŒë§¤ìˆ˜ëŸ‰': 'ìˆ˜ëŸ‰',
    'quantity': 'ìˆ˜ëŸ‰',
    'ë§¤ì¶œ': 'ë§¤ì¶œì•¡',
    'sales': 'ë§¤ì¶œì•¡',
    'amount': 'ë§¤ì¶œì•¡',
    'Amount': 'ë§¤ì¶œì•¡'
}

def normalize_keys(row):
    new_row = {}
    for key, value in row.items():
        normalized_key = COLUMN_ALIASES.get(key.strip(), key.strip())
        new_row[normalized_key] = value
    return new_row

# í™˜ìœ¨ ê°€ì ¸ì˜¤ê¸°
def fetch_exchange_rate(base='USD', target='KRW'):
    test_mode = os.environ.get('TEST_MODE', 'false').lower() == 'true'
    if test_mode:
        fake_rate = 1300.0
        print("ğŸ”ª í…ŒìŠ¤íŠ¸ ëª¨ë“œ í™•ìœ¨ ì ìš© ({fake_rate})", file=sys.stderr)
        return fake_rate
    api_key = "63fdc587845af979431c25fe"
    url = f"https://v6.exchangerate-api.com/v6/{api_key}/latest/{base}"
    try:
        res = requests.get(url, timeout=5)
        data = res.json()
        return data.get('conversion_rates', {}).get(target)
    except Exception as e:
        print(f"í™˜ìœ¨ API ì˜¤ë¥˜: {e}", file=sys.stderr)
        return None
    
# DB ì €ì¥
def insert_forecast_to_db(forecast_dict, project_id=None):
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        for date_str, amount in forecast_dict.items():
            raw_data = {
                "name": "ì˜ˆì¸¡ë°ì´í„°",
                "amount": amount,
                "date": date_str
            }
            print(f"ğŸ“¥ ì €ì¥ ëŒ€ìƒ: {raw_data}", file=sys.stderr)
            cursor.execute(
                "INSERT INTO products (project_id, raw_data) VALUES (%s, %s)",
                (project_id, json.dumps(raw_data, ensure_ascii=False))
            )
        conn.commit()
        cursor.close()
        conn.close()
    except Exception as e:
        print(f"DB ì €ì¥ ì˜¤ë¥˜: {e}", file=sys.stderr)

# ë¶„ì„ í•¨ìˆ˜
def analyze_combined_dataframe(df, project_id=None):
    df['ë‚ ì§œ'] = pd.to_datetime(df['ë‚ ì§œ'], errors='coerce')
    
    df['ë§¤ì¶œì•¡'] = pd.to_numeric(df['ë§¤ì¶œì•¡'], errors='coerce')
    print("ğŸ“Š Prophet ì…ë ¥ìš© ë°ì´í„°:", file=sys.stderr)
    print(df_parsed[['ë‚ ì§œ', 'ë§¤ì¶œì•¡']].head(10), file=sys.stderr)

    df = df.dropna(subset=['ë‚ ì§œ', 'ë§¤ì¶œì•¡'])
    if df.empty or len(df) < 10:
        raise ValueError("ìœ íš¨í•œ ë¶„ì„ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")

    total_sales = df['ë§¤ì¶œì•¡'].sum()
    avg_sales = df['ë§¤ì¶œì•¡'].mean()
    max_sales = df['ë§¤ì¶œì•¡'].max()
    min_sales = df['ë§¤ì¶œì•¡'].min()

    df_prophet = df[['ë‚ ì§œ', 'ë§¤ì¶œì•¡']].rename(columns={'ë‚ ì§œ': 'ds', 'ë§¤ì¶œì•¡': 'y'})
    df_prophet = df_prophet.groupby('ds', as_index=False).agg({'y': 'sum'}).sort_values('ds')
    df_prophet = df_prophet[(df_prophet['y'] >= 0) & (df_prophet['y'] <= 1e9)]  # ì˜ˆì¸¡ê°’ ìœ íš¨ì„± í•„í„°ë§
    if df_prophet.empty or len(df_prophet) < 10:
        raise ValueError("ì˜ˆì¸¡í•  ìˆ˜ ìˆëŠ” ìœ íš¨í•œ ë°ì´í„°ê°€ ì¡´ì¬í•˜ì§€ ì•Šê±°ë‚˜ ë„ˆë¬´ ì ìŠµë‹ˆë‹¤.")

    model = Prophet()
    model.fit(df_prophet)

    future = pd.date_range(start=df_prophet['ds'].max() + pd.Timedelta(days=1), periods=7)
    forecast = model.predict(pd.DataFrame({'ds': future}))

    forecast_dict = {
        str(row['ds'].date()): int(round(row['yhat'])) if pd.notna(row['yhat']) else 0
        for _, row in forecast[['ds', 'yhat']].iterrows()
    }
    insert_forecast_to_db(forecast_dict, project_id)

    return {
        'total_sales': int(total_sales),
        'avg_sales': int(avg_sales),
        'max_sales': int(max_sales),
        'min_sales': int(min_sales),
        'forecast_next_7_days': forecast_dict
    }

# ì‹¤í–‰ ì§„ì…ì 
if __name__ == '__main__':
    args = sys.argv[1:]
    project_id = None

    if '--project' in args:
        idx = args.index('--project')
        if idx + 1 < len(args):
            project_id = int(args[idx + 1])
            del args[idx:idx + 2]

    if project_id is not None:
        try:
            conn = get_db_connection()
            df = pd.read_sql("SELECT raw_data FROM products WHERE project_id = %s ORDER BY uploaded_at ASC", conn, params=(project_id,))
            conn.close()

            raw_parsed = [json.loads(item['raw_data']) for _, item in df.iterrows()]

            # âœ… ì¤‘ë³µ ë° íŒŒìƒ ì»¬ëŸ¼ ì œê±°
            cleaned_rows = []
            for row in raw_parsed:
                row = {k.strip().replace('\ufeff', ''): v for k, v in row.items() if k}
                for bad_key in ['filename', 'index', '_merge']:
                    row.pop(bad_key, None)
                row = {k: v for k, v in row.items() if not re.match(r"^_\\d+$|^Unnamed", k)}
                row = normalize_keys(row)
                cleaned_rows.append(row)

            df_parsed = pd.DataFrame(cleaned_rows)
            print(f"âœ… ì •ì œ í›„ ì»¬ëŸ¼: {df_parsed.columns.tolist()}", file=sys.stderr)
            print(f"âœ… ìƒ˜í”Œ 5í–‰:\n{df_parsed.head()}", file=sys.stderr)

            columns = df_parsed.columns.tolist()
            date_col = guess_column(columns, ["ë‚ ì§œ", "date", "íŒë§¤ì¼", "Date"])
            amount_col = guess_column(columns, ["ë§¤ì¶œ", "ë§¤ì¶œì•¡", "ê¸ˆì•¡", "sales", "amount", "Amount"])
            currency_col = guess_column(columns, ["í†µí™”", "currency", "Currency"])

            if not date_col or not amount_col:
                raise ValueError("ë‚ ì§œ ë˜ëŠ” ë§¤ì¶œ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
            rate = fetch_exchange_rate()
            if rate and currency_col in df_parsed.columns:
                df_parsed[currency_col] = df_parsed[currency_col].astype(str).str.upper()
                usd_mask = df_parsed[currency_col] == 'USD'
                df_parsed.loc[usd_mask, amount_col] = df_parsed.loc[usd_mask, amount_col].astype(float) * rate

            # ë‚ ì§œ ì²˜ë¦¬ ë° ë³´ì •
            if pd.api.types.is_numeric_dtype(df_parsed[date_col]):
                # ì—‘ì…€ ìˆ«ìí˜• ë‚ ì§œ â†’ ë‚ ì§œë¡œ ë³€í™˜
                df_parsed['ë‚ ì§œ'] = pd.to_datetime('1899-12-30') + pd.to_timedelta(df_parsed[date_col], unit='D')
            else:
                df_parsed['ë‚ ì§œ'] = pd.to_datetime(df_parsed[date_col], errors='coerce')
                if df_parsed['ë‚ ì§œ'].isna().all() or (
                    df_parsed['ë‚ ì§œ'].dt.year.nunique() == 1 and df_parsed['ë‚ ì§œ'].dt.year.mode().iloc[0] == 1970
                ):
                    df_parsed['ë‚ ì§œ'] = pd.to_datetime('1899-12-30') + pd.to_timedelta(df_parsed[date_col], unit='D')

            # ë§¤ì¶œì•¡ ì •ì œ (ì‰¼í‘œ ì œê±°)
            df_parsed[amount_col] = df_parsed[amount_col].astype(str).str.replace(",", "").str.strip()
            df_parsed['ë§¤ì¶œì•¡'] = pd.to_numeric(df_parsed[amount_col], errors='coerce')
            if df_parsed['ë§¤ì¶œì•¡'].isna().all():
                raise ValueError("ë§¤ì¶œì•¡ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

            df_parsed = df_parsed.dropna(subset=['ë‚ ì§œ', 'ë§¤ì¶œì•¡'])
            result = analyze_combined_dataframe(df_parsed, project_id)
            print(json.dumps(result, ensure_ascii=False), file=sys.stdout)
        except Exception as e:
            print(json.dumps({'error': f'ë¶„ì„ ì‹¤íŒ¨: {str(e)}'}, ensure_ascii=False), file=sys.stdout)
