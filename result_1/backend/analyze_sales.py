# -*- coding: utf-8 -*-
import pandas as pd
from prophet import Prophet
import re
import matplotlib
matplotlib.use('Agg')
import io
import sys
import json
import os
import requests
import mysql.connector
import chardet

#MySQL ì—°ê²°
def get_db_connection():
    return mysql.connector.connect(
        host='localhost',
        user='root',
        password='0000',
        database='dashboard_db'
    )

#ì»¬ëŸ¼ ì¶”ì • í•¨ìˆ˜
def guess_column(candidates, options):
    for col in candidates:
        for opt in options:
            if re.search(opt, col, re.IGNORECASE):
                return col
    return None

def fetch_exchange_rate(base='USD', target='KRW'):
    api_key = "63fdc587845af979431c25fe"
    url = f"https://v6.exchangerate-api.com/v6/{api_key}/latest/{base}"

    try:
        res = requests.get(url, timeout=5)  # âœ… timeout ì¶”ê°€!
        data = res.json()
        rate = data.get('conversion_rates', {}).get(target)

        if not rate:
            print(f"âš ï¸ í™˜ìœ¨ ì •ë³´ ì—†ìŒ: {data}", file=sys.stderr)
            return None

        return rate
    except Exception as e:
        print(f"âŒ í™˜ìœ¨ API ì˜¤ë¥˜: {e}", file=sys.stderr)
        return None
    
#ì¸ì½”ë”© ê°ì§€ í•¨ìˆ˜
def detect_encoding(file_stream):
    rawdata = file_stream.read()
    result = chardet.detect(rawdata)
    encoding = result['encoding'] or 'utf-8'
    print(f"ğŸ“¡ ê°ì§€ëœ ì¸ì½”ë”©: {encoding}", file=sys.stderr)
    file_stream.seek(0)
    return encoding

#íŒŒì¼ì—ì„œ DataFrame ì½ê¸°
def read_file_as_dataframe(file_stream, filename):
    ext = os.path.splitext(filename)[-1].lower()
    try:
        if ext in ['.xls', '.xlsx']:
            file_stream.seek(0)
            df = pd.read_excel(file_stream)
        elif ext == '.csv':
            encoding = detect_encoding(file_stream)
            file_stream.seek(0)
            df = pd.read_csv(file_stream, encoding=encoding)
        else:
            return None, f"{filename}: ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤. (csv, xlsxë§Œ ê°€ëŠ¥)"

        df.columns = [str(col) for col in df.columns]
        df.columns = df.columns.str.strip().str.replace('\ufeff', '')

        if any("ï¿½" in col for col in df.columns):
            print(f"âš ï¸ ì¸ì½”ë”© ê¹¨ì§ ê°ì§€ë¨ â†’ ê°ì§€ëœ ì¸ì½”ë”©: {encoding}", file=sys.stderr)

        columns = df.columns.tolist()

        date_col = guess_column(columns, ["ë‚ ì§œ", "ë‚ ì", "date", "Date", "íŒë§¤ì¼", "íŒë§¤ì¼ì", "ì‘ì„±ì¼", "ì¼ì",
                                            "ì‘ì„±ì¼ì", 'ê±°ë˜ì¼', "ê±°ë˜ì¼ì", 'êµ¬ë§¤ì¼', "êµ¬ë§¤ì¼ì", 'ë“±ë¡ì¼', "ë“±ë¡ì¼ì",
                                            'ì£¼ë¬¸ì¼', "ì£¼ë¬¸ì¼ì", 'ì²˜ë¦¬ì¼', "ì²˜ë¦¬ì¼ì", 'ê²°ì œì¼', "ê²°ì œì¼ì"])
        sales_col = guess_column(columns, ['ë§¤ì¶œ', 'ë§¤ì¶œì•¡', 'sales', "Sales", 'revenue', 'Revenue', "ê¸ˆì•¡",
                                            'íŒë§¤ê¸ˆì•¡', 'ì´ì•¡', 'ìˆ˜ìµ', 'amount', "Amount", 'ì‹¤ë§¤ì¶œ', 'ë§¤ì¶œí•©ê³„',
                                            'ì´ë§¤ì¶œ', 'ê²°ì œê¸ˆì•¡', 'order total', 'total price', 'ê±°ë˜ê¸ˆì•¡'])

        if not date_col or not sales_col:
            print(f"âŒ ì»¬ëŸ¼ ì¶”ë¡  ì‹¤íŒ¨ - columns: {columns}", file=sys.stderr)
            return None, f"{filename}: ë‚ ì§œ ë˜ëŠ” ë§¤ì¶œì•¡ ì»¬ëŸ¼ì„ ìë™ìœ¼ë¡œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        df.rename(columns={date_col: 'ë‚ ì§œ', sales_col: 'ë§¤ì¶œì•¡'}, inplace=True)
        df['ë‚ ì§œ'] = pd.to_datetime(df['ë‚ ì§œ'], errors='coerce')
        df['ë§¤ì¶œì•¡'] = pd.to_numeric(df['ë§¤ì¶œì•¡'], errors='coerce')
        df = df.dropna(subset=['ë‚ ì§œ', 'ë§¤ì¶œì•¡'])
        if df.empty:
            return None, f"{filename}: ìœ íš¨í•œ ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŒ"
        return df[['ë‚ ì§œ', 'ë§¤ì¶œì•¡']], None
    except Exception as e:
        return None, f"{filename}: íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"

# ğŸ“ˆ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ DBì— ì €ì¥
def insert_forecast_to_db(forecast_dict, project_id=None):
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        for date_str, amount in forecast_dict.items():
            raw_data = {
                "name": "ì˜ˆì¸¡ë°ì´í„°",
                "amount": amount,
                "date": date_str
            }
            cursor.execute(
                "INSERT INTO products (project_id, raw_data) VALUES (%s, %s)",
                (project_id, json.dumps(raw_data, ensure_ascii=False))
            )
        conn.commit()
        cursor.close()
        conn.close()
    except Exception as e:
        print(f"DB ì €ì¥ ì˜¤ë¥˜: {e}", file=sys.stderr)

# ğŸ“Š ë¶„ì„ ë©”ì¸ í•¨ìˆ˜
def analyze_combined_dataframe(df, project_id=None):
    df['ë‚ ì§œ'] = pd.to_datetime(df['ë‚ ì§œ'], errors='coerce')
    df['ë§¤ì¶œì•¡'] = pd.to_numeric(df['ë§¤ì¶œì•¡'], errors='coerce')
    df = df.dropna(subset=['ë‚ ì§œ', 'ë§¤ì¶œì•¡'])

    if df.empty or len(df) < 10:
        raise ValueError("ìœ íš¨í•œ ë¶„ì„ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
    
    total_sales = df['ë§¤ì¶œì•¡'].sum()
    avg_sales = df['ë§¤ì¶œì•¡'].mean()
    max_sales = df['ë§¤ì¶œì•¡'].max()
    min_sales = df['ë§¤ì¶œì•¡'].min()

    df['z_score'] = (df['ë§¤ì¶œì•¡'] - avg_sales) / df['ë§¤ì¶œì•¡'].std()
    df['is_outlier'] = df['z_score'].abs() > 2

    df_prophet = df[['ë‚ ì§œ', 'ë§¤ì¶œì•¡']].rename(columns={'ë‚ ì§œ': 'ds', 'ë§¤ì¶œì•¡': 'y'})
    df_prophet['ds'] = pd.to_datetime(df_prophet['ds'], errors='coerce')
    df_prophet['y'] = pd.to_numeric(df_prophet['y'], errors='coerce')
    df_prophet = df_prophet.dropna()

    # âœ… ë‚ ì§œ ê¸°ì¤€ groupby
    df_prophet = df_prophet.groupby('ds', as_index=False).agg({'y': 'sum'})
    df_prophet = df_prophet.sort_values('ds')

    if df_prophet.empty or len(df_prophet) < 10:
        raise ValueError("ì˜ˆì¸¡í•  ìˆ˜ ìˆëŠ” ìœ íš¨í•œ ë°ì´í„°ê°€ ì¡´ì¬í•˜ì§€ ì•Šê±°ë‚˜ ë„ˆë¬´ ì ìŠµë‹ˆë‹¤.")

    try:
        model = Prophet()
        model.fit(df_prophet)
        print("ğŸ“ˆ Prophet í•™ìŠµ ì™„ë£Œ", file=sys.stderr)
    except Exception as e:
        print(f"âŒ Prophet í•™ìŠµ ì‹¤íŒ¨: {e}", file=sys.stderr)
        raise

    last_date = df_prophet['ds'].max()
    future_dates = pd.date_range(start=last_date + pd.Timedelta(days=1), periods=7)
    future = pd.DataFrame({'ds': future_dates})
    forecast = model.predict(future)
    forecast_dict = {}

    for _, row in forecast[['ds', 'yhat']].iterrows():
        date = row['ds'].date()
        value = row['yhat']
        if pd.isna(value) or not pd.api.types.is_number(value) or value < 0 or value > 1e9:
            value = 0
        forecast_dict[str(date)] = int(round(value))

    insert_forecast_to_db(forecast_dict, project_id)
    print("ğŸ§¾ ì˜ˆì¸¡ ê²°ê³¼ forecast_dict:", file=sys.stderr) 
    print(forecast_dict, file=sys.stderr)

    return {
        'total_sales': int(total_sales),
        'avg_sales': int(avg_sales),
        'max_sales': int(max_sales),
        'min_sales': int(min_sales),
        'forecast_next_7_days': forecast_dict
    }

def is_valid_dataframe(df):
    if df is None or df.empty:
        return False
    if 'ë‚ ì§œ' not in df.columns or 'ë§¤ì¶œì•¡' not in df.columns:
        return False
    if df['ë‚ ì§œ'].isna().all() or df['ë§¤ì¶œì•¡'].isna().all():
        return False
    return True

# ğŸš€ CLI ì§„ì…ì 
if __name__ == '__main__':
    args = sys.argv[1:]
    project_id = None

    if '--project' in args:
        idx = args.index('--project')
        if idx + 1 < len(args):
            project_id = int(args[idx + 1])
            del args[idx:idx+2]

    if args:
        input_paths = args
        combined_df = []
        errors = []

        for path in input_paths:
            with open(path, 'rb') as f:
                file_stream = io.BytesIO(f.read())
                df, err = read_file_as_dataframe(file_stream, os.path.basename(path))
                if df is not None:
                    df['ë‚ ì§œ'] = pd.to_datetime(df['ë‚ ì§œ'], errors='coerce')
                    df['ë§¤ì¶œì•¡'] = pd.to_numeric(df['ë§¤ì¶œì•¡'], errors='coerce')
                    df = df.dropna(subset=['ë‚ ì§œ', 'ë§¤ì¶œì•¡'])
                    combined_df.append(df)
                else:
                    errors.append({'filename': os.path.basename(path), 'error': err})

        if not combined_df:
            print(json.dumps({'error': 'ëª¨ë“  íŒŒì¼ì´ ë¶„ì„ ë¶ˆê°€', 'details': errors}, ensure_ascii=False), file=sys.stdout)
        else:
            merged_df = pd.concat(combined_df, ignore_index=True)
            try:
                result = analyze_combined_dataframe(merged_df, project_id)
                print(json.dumps(result, ensure_ascii=False), file=sys.stdout)
            except Exception as e:
                print(json.dumps({'error': str(e)}, ensure_ascii=False), file=sys.stdout)

    elif project_id is not None:
        try:
            conn = get_db_connection()
            query = "SELECT raw_data FROM products WHERE project_id = %s ORDER BY uploaded_at ASC"
            df = pd.read_sql(query, conn, params=(project_id,))
            conn.close()

            raw_parsed = [json.loads(item['raw_data']) for _, item in df.iterrows()]

            df_parsed = pd.DataFrame(raw_parsed)
            df_parsed.columns = df_parsed.columns.str.strip().str.replace('\ufeff', '') 
            df_parsed = df_parsed.loc[:, ~df_parsed.columns.duplicated()]
            print(f"ğŸ“‹ df_parsed.columns = {df_parsed.columns.tolist()}", file=sys.stderr)
            print(f"ğŸ“‹ df_parsed ìƒ˜í”Œ 5í–‰:\n{df_parsed.head()}", file=sys.stderr)

            if 'name' in df_parsed.columns:
                df_parsed = df_parsed[df_parsed['name'] != 'ì˜ˆì¸¡ë°ì´í„°']
                print("âœ… 'ì˜ˆì¸¡ë°ì´í„°' í–‰ ì œê±° ì™„ë£Œ", file=sys.stderr)

            df_parsed.columns = df_parsed.columns.str.strip().str.replace('\ufeff', '')
            if any("ï¿½" in col for col in df_parsed.columns):
                print(f"âš ï¸ DB ê¸°ë°˜ ë¶„ì„ì—ì„œ ê¹¨ì§„ ì»¬ëŸ¼ ê°ì§€ë¨ â†’ {df_parsed.columns.tolist()}", file=sys.stderr)
            columns = df_parsed.columns.tolist()

            date_col = guess_column(columns, ["ë‚ ì§œ", "ë‚ ì", "date", "Date", "íŒë§¤ì¼", "íŒë§¤ì¼ì", "ì‘ì„±ì¼", "ì¼ì",
                                               "ì‘ì„±ì¼ì", 'ê±°ë˜ì¼', "ê±°ë˜ì¼ì", 'êµ¬ë§¤ì¼', "êµ¬ë§¤ì¼ì", 'ë“±ë¡ì¼', "ë“±ë¡ì¼ì",
                                               'ì£¼ë¬¸ì¼', "ì£¼ë¬¸ì¼ì", 'ì²˜ë¦¬ì¼', "ì²˜ë¦¬ì¼ì", 'ê²°ì œì¼', "ê²°ì œì¼ì"])
            sales_col = guess_column(columns, ['ë§¤ì¶œ', 'ë§¤ì¶œì•¡', 'sales', "Sales", 'revenue', 'Revenue', "ê¸ˆì•¡",
                                               'íŒë§¤ê¸ˆì•¡', 'ì´ì•¡', 'ìˆ˜ìµ', 'amount', "Amount", 'ì‹¤ë§¤ì¶œ', 'ë§¤ì¶œí•©ê³„',
                                               'ì´ë§¤ì¶œ', 'ê²°ì œê¸ˆì•¡', 'order total', 'total price', 'ê±°ë˜ê¸ˆì•¡'])
            currency_col = guess_column(columns, ['í†µí™”', 'currency', 'Currency', 'í™”í', 'í™”íë‹¨ìœ„'])
            
            print(f"âœ… STEP 4: ì¶”ë¡ ëœ date_col = {date_col}, sales_col = {sales_col}", file=sys.stderr)

            if not date_col or not sales_col:
                raise ValueError("ë‚ ì§œ ë˜ëŠ” ë§¤ì¶œ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

            rate = fetch_exchange_rate()
                
            df_parsed['ë‚ ì§œ'] = pd.to_datetime(df_parsed[date_col], errors='coerce')
            # ë‚ ì§œê°€ ì „ë¶€ 1970ë…„ì´ê±°ë‚˜, to_datetime í–ˆëŠ”ë° ê°’ì´ ì´ìƒí•˜ë©´ ì²˜ë¦¬
            try_excel_numeric = False

            # 1. ì „ë¶€ NaTê±°ë‚˜
            if df_parsed['ë‚ ì§œ'].isna().all():
                try_excel_numeric = True

            # 2. ë‚ ì§œê°€ ê±°ì˜ ë‹¤ 1970ë…„ìœ¼ë¡œ ë‚˜ì˜¤ëŠ” ê²½ìš°
            elif df_parsed['ë‚ ì§œ'].dt.year.nunique() == 1 and df_parsed['ë‚ ì§œ'].dt.year.mode().iloc[0] == 1970:
                try_excel_numeric = True

            # 3. íƒ€ì…ì´ ì „ë¶€ float/intì´ë©´ ê°€ëŠ¥ì„± ìˆìŒ
            elif df_parsed[date_col].apply(lambda x: isinstance(x, (int, float))).all():
                try_excel_numeric = True

            if try_excel_numeric:
                df_parsed['ë‚ ì§œ'] = pd.to_datetime('1899-12-30') + pd.to_timedelta(df_parsed[date_col], unit='D')
            
            df_parsed['ë§¤ì¶œì•¡'] = pd.to_numeric(df_parsed[sales_col], errors='coerce')

            if rate:
                if currency_col and currency_col in df_parsed.columns:
                    df_parsed[currency_col] = df_parsed[currency_col].astype(str).str.upper()
                    usd_mask = df_parsed[currency_col] == 'USD'
                    df_parsed.loc[usd_mask, 'ë§¤ì¶œì•¡'] = df_parsed.loc[usd_mask, 'ë§¤ì¶œì•¡'] * rate
                    print(f"ğŸ“ˆ í™˜ìœ¨ ì ìš© ì™„ë£Œ: 1 USD = {rate} KRW", file=sys.stderr)
                else:
                    print("âš ï¸ í™˜ìœ¨ ì •ë³´ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í•´ í™˜ìœ¨ ì ìš©ì„ ê±´ë„ˆëœë‹ˆë‹¤.", file=sys.stderr)

            df_parsed = df_parsed.dropna(subset=['ë‚ ì§œ', 'ë§¤ì¶œì•¡'])

            result = analyze_combined_dataframe(df_parsed, project_id)
            print(json.dumps(result, ensure_ascii=False), file=sys.stdout)
       
        except Exception as e:
            print(json.dumps({'error': f'í”„ë¡œì íŠ¸ ê¸°ë°˜ DB ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {str(e)}'}, ensure_ascii=False), file=sys.stdout)
